## 微调常见问题分析2

1. 如何训练自己的大模型？
   
1) 数据收集和准备：首先，需要收集与目标任务和领域相关的大规模数据集。这可以包括从互联网上爬取数据、使用公开数据集或者与合作伙伴合作获取数据。然后，对数据进行预处理和清洗，包括去除噪声、处理缺失值、标准化数据等。
2) 模型设计和架构选择：根据任务的特点和目标，选择适合的模型架构。可以基于已有的模型进行修改和调整，或者设计全新的模型。常见的大模型架构包括深度神经网络（如卷积神经网络、循环神经网络、Transformer等）和预训练语言模型（如BERT、GPT等）。
3) 数据划分和预处理：将数据集划分为训练集、验证集和测试集。训练集用于模型的训练，验证集用于调整超参数和模型选择，测试集用于最终评估模型的性能。进行数据预处理，如分词、编码、标记化、特征提取等，以便输入到模型中。
4) 模型训练：使用训练集对模型进行训练。训练过程中，需要选择合适的***优化算法、损失函数和学习率等超参数**，并进行适当的调整和优化。可以使用GPU或者分布式训练来加速训练过程
5) 模型调优和验证：使用验证集对训练过程中的模型进行调优和验证。根据验证集的性能指标，调整模型的超参数、网络结构或者其他相关参数，以提升模型的性能。
6) 模型评估和测试：使用测试集对最终训练好的模型进行评估和测试。计算模型的性能指标，如准确率、召回率、F1值等，评估模型的性能和泛化能力。
7) 模型部署和优化：将训练好的模型部署到实际应用中。根据实际需求，对模型进行进一步的优化和调整，以提高模型的效率和性能。

2. 预训练和微调哪个阶段注入知识的？

预训练和微调两个阶段都可以注入知识，但它们注入知识的方式和范围略有不同。

在预训练阶段，模型通过大规模的未标注数据进行训练，从中学习语言的统计特征、语义知识和语言规律。预训练的目的是让模型建立起对语言的基本理解和概念，并学习到一般性的语言表示。这种预训练过程注入了通用的语言知识，并可以迁移到各种下游任务中。

在微调阶段，预训练的模型通过在特定任务上使用带标注的数据进行微调，以适应具体任务的要求。在微调过程中，模型通过接触任务特定的数据和标签，进一步调整和优化模型的参数，使其更好地适应任务的特定特征和要求。微调阶段注入的是与任务相关的知识和信息。

综上所述，预训练阶段主要注入通用的语言知识和表示能力，而微调阶段则注入与任务相关的知识和特定要求。预训练阶段使得模型具备了一定的语言理解能力，而微调阶段则将这种能力与具体任务相结合，使模型在任务上表现更好。预训练和微调两个阶段的结合，可以有效地提高模型的性能和泛化能力。

3. 预训练和SFT操作有什么不同

大语言模型的预训练和有监督微调（Supervised Fine-Tuning）是两个不同的操作，它们在目标、数据和训练方式等方面存在一些区别。

目标：

    预训练的目标是通过无监督学习从大规模的文本语料库中学习语言模型的表示能力和语言知识。预训练的目标通常是通过自我预测任务，例如***掩码语言模型（Masked Language Model，MLM）或下一句预测（Next Sentence Prediction，NSP）***等，来训练模型。

    有监督微调的目标是在特定的任务上进行训练，例如文本分类、命名实体识别等。在有监督微调中，模型会利用预训练阶段学到的语言表示和知识，通过有监督的方式调整模型参数，以适应特定任务的要求。

数据：

    在预训练阶段，大语言模型通常使用大规模的无标签文本数据进行训练，例如维基百科、网页文本等。这些数据没有特定的标签或任务信息，模型通过自我预测任务来学习语言模型。
    
    在有监督微调中，模型需要使用带有标签的任务相关数据进行训练。这些数据通常是人工标注的，包含了输入文本和对应的标签或目标。模型通过这些标签来进行有监督学习，调整参数以适应特定任务。

训练方式：

    预训练阶段通常使用无监督的方式进行训练，模型通过***最大化预训练任务的目标函数*** 来学习语言模型的表示能力。
    
    有监督微调阶段则使用有监督的方式进行训练，模型通过***最小化损失函数***来学习任务相关的特征和模式。在微调阶段，通常会使用预训练模型的参数作为初始参数，并在任务相关的数据上进行训练。

总的来说，预训练和有监督微调是大语言模型训练的两个阶段，目标、数据和训练方式等方面存在差异。预训练阶段通过无监督学习从大规模文本数据中学习语言模型，而有监督微调阶段则在特定任务上使用带有标签的数据进行有监督学习，以适应任务要求。

4. 领域模型词表扩增是不是有必要的？

领域模型的词表扩增可以有助于提升模型在特定领域任务上的性能，但是否有必要取决于具体的情况。以下是一些考虑因素：

1) 领域特定词汇：如果目标领域中存在一些特定的词汇或术语，而这些词汇在通用的预训练模型的词表中没有覆盖到，那么词表扩增就是必要的。通过将这些领域特定的词汇添加到模型的词表中，可以使模型更好地理解和处理这些特定的词汇。
2) 领域特定上下文：在某些领域任务中，词汇的含义可能会受到特定上下文的影响。例如，在医学领域中，同一个词汇在不同的上下文中可能具有不同的含义。如果领域任务中的上下文与通用预训练模型的训练数据中的上下文有较大差异，那么词表扩增可以帮助模型更好地理解和处理领域特定的上下文。
3) 数据稀缺性：如果目标领域的训练数据相对较少，而通用预训练模型的词表较大，那么词表扩增可以帮助模型更好地利用预训练模型的知识，并提升在目标领域任务上的性能。

需要注意的是，词表扩增可能会增加模型的计算和存储成本。因此，在决定是否进行词表扩增时，需要综合考虑领域特定词汇的重要性、数据稀缺性以及计算资源的限制等因素。有时候，简单的词表截断或者使用基于规则的方法来处理领域特定词汇也可以取得不错的效果。最佳的词表扩增策略会因特定任务和领域的需求而有所不同，建议根据具体情况进行评估和实验。

在微调过程中，扩充模型的词表（vocabulary expansion）是一个常见的操作，特别是在处理特定领域的任务时，例如医学、法律、或技术文档等。这些领域通常有大量的特定术语，模型的原始词表可能无法覆盖，导致未登录词（OOV，Out-of-Vocabulary）问题。通过扩展词表，可以让模型更好地适应这些领域。

操作步骤：

	1.	收集领域数据：获取足够多的领域文本，例如医疗文档、法律合同、技术说明书等。
	2.	提取独特术语：
        •	使用分词工具（如 spaCy、NLTK 或自定义正则表达式）对领域文本进行分词。
        •	统计单词频率，过滤出高频但未包含在原始词表中的术语。
	3.	检查现有词表：确定这些领域术语哪些已经包含在模型的现有词表中，哪些需要新增。

工具：
	•	Counter 模块（用于统计词频）。
	•	transformers 库的 AutoTokenizer 类（检查术语是否在词表中）。

    扩充模型词表

    词表扩展涉及在模型的分词器（Tokenizer）和嵌入层（Embedding Layer）中添加新的词。以下是详细的步骤：

    (1) 扩展分词器词表
        •	修改分词器的 vocab，将新的领域术语加入。
        •	调整分词器配置以支持新的词表大小。

    (2) 扩展嵌入层
        •	词表扩展后，原始模型的嵌入层大小与新的词表大小不匹配。需要重新初始化嵌入层，并将新增词的嵌入向量随机初始化。
    注意：
        •	新增词的嵌入向量会被随机初始化，训练时需要通过微调更新这些向量。

    微调领域数据

    扩展词表后，使用领域数据对模型进行微调，更新新增词的嵌入向量和其他模型参数。
    准备微调数据
	•	确保领域数据覆盖新增的词汇。
	•	使用新的分词器对领域数据进行分词，并生成输入。

领域模型词表扩展的优缺点

优点：
	1.	覆盖领域术语：扩展词表后，模型可以直接处理领域特定的词汇，避免未登录词问题。
	2.	提升模型效果：对领域任务（如分类、生成等）具有显著的性能提升。
	3.	减少分词碎片化：减少将领域术语切分为多个子词的情况，提升表示质量。

缺点：
	1.	额外训练开销：新增词的嵌入向量需要随机初始化，模型需要更多的训练数据和时间来优化。
	2.	潜在过拟合：如果领域数据不足，模型可能会对新增词过拟合。
	3.	模型尺寸增加：词表扩展后，嵌入层大小会增加，模型内存占用更高。

与替代方法对比

如果词表扩展不可行，可以考虑以下替代方法：
	1.	子词分词改进：通过优化分词器的参数（如 BPE 或 WordPiece 算法）以更好地适应领域文本。
	2.	知识注入：通过 Adapter 或 LoRA 等方法，注入领域知识，无需修改词表。
	3.	外部知识检索：使用检索增强生成（RAG）方法，通过外部文档补充领域信息。

扩展词表通常在高专业化领域任务中非常有效，但需要结合数据规模和模型复杂度谨慎评估。    

