
## 机器视觉的一些主要任务和挑战

### multi-task

天然的多任务训练，满足不同层次的语义粒度需求。主要实现方式，将图像和文本嵌入到一个共享的多模态嵌入空间，通过相似性度量（如余弦相似度）实现对齐。通过注意力机制，关联图像的不同区域与语义描述的不同部分。例如，图像中的“红色区域”对应文本描述中的“红色汽车”。	使用特殊的损失函数（如对比损失、三元组损失）来优化视觉和语义的对齐精度。
![multi-tasks-result](./Florence2/multi-tasks-prompt.png)

主要可以分成以下三个粒度层次：
![multi-tasks-result](./Florence2/multi-tasks-result.png)
   1. image-level understanding
        识别物体，任务，建筑等。
        生成标题caption，消息caption和描述等
   
   2. region/pixel-level understanding
        精确识别物理，同时包括物体的坐标信息。包括后续的子图的切割，图片掩码，背景移除等
   
   3. Fine-gained visual-semanic aligement   细粒度视觉-语义对齐
        Fine-grained Visual-Semantic Alignment 是机器视觉领域中连接视觉和语义信息的重要技术，它强调细节的理解和精确的匹配，广泛应用于图像检索、分类和标注等任务。从图像库中找到与给定文本描述高度匹配的图像，或者从文本描述中检索相关的图像。

        Fine-grained（细粒度）：不仅要识别物体
            •	强调对视觉对象或场景的细致理解。
            •	不仅识别大类别（如“鸟”），还需要区分子类别（如“麻雀”和“燕子”）。
                    文本描述可能涉及图像中的细节，例如“黑色的运动鞋，带有白色鞋带”，系统需要理解图像中的细节并与描述准确匹配。
                    在高度相似的图像类别中进行区分。	例如，区分不同品种的鸟类（如“蓝翡翠”和“普通翠鸟”）或不同型号的汽车。视觉特征（如颜色、羽毛图案、车灯形状）需要与语义标签精确对齐。

            •	涉及视觉细节的精确捕捉，例如颜色、纹理、形状差异。为图像生成自然语言描述。
                    描述中的细节需要与图像特征精确匹配，例如“一个穿红色裙子的女人站在沙滩上”。
                    系统必须捕捉到特定的视觉细节并将其表达为语言。
        
        Visual-Semantic Alignment（视觉-语义对齐）:
            同时利用视觉和语言信息进行联合建模，需要在视觉特征和语义表示（如嵌入空间）之间建立细粒度的关联。例如，用于生成精确的视觉问答（Visual Question Answering）或更精准的跨模态搜索

            •	建立视觉信息（如图像或视频）与语义信息（如标签、文本描述）之间的映射关系。
	        •	对齐可以是全局的（整个图像的描述）或局部的（特定区域的描述）。





### florence 的主要应对和实现
1. dataset
   
数据集FLD-5B: 126,000,000张图片包含5,400,000,000标注信息。包含不同层面的“语义粒度”semantic granularity 信息，满足不同技术任务中不同层次的语义粒度信息。
![data-process.png](./Florence2/data-process.png)
最后没张图片得到的标注结果：
![FLD-5B](./Florence2/FLD-5B.png)
