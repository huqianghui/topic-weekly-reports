## OpenAI o1 模型系统卡摘要

### overview

o1 模型系列通过大规模强化学习进行训练，以使用思维链进行推理。
这些高级推理功能为提高模型的安全性和稳健性提供了新的途径。
特别是，模型可以在响应可能不安全的提示时根据上下文推理安全策略。这导致在某些风险基准上具有最先进的性能，例如生成非法建议、选择刻板的响应以及屈服于已知的越狱。
在回答之前，训练模型整合一条思维链有可能带来巨大的好处，同时也会增加因智力提高而产生的潜在风险。
结果强调了构建稳健的对齐方法、广泛压力测试其有效性并维护细致的风险管理协议的必要性。
对 OpenAI o1 和 OpenAI o1-mini 模型进行的安全工作，包括安全评估、外部红队和准备框架评估。


### Chain-of-Thought 安全

o1 模型的主要区别特征之一是它们在尝试解决问题时使用思维链。除了监控模型的输出外，还一直对监控其潜在思维的前景感到兴奋。
到目前为止，这种潜在思维只能以激活的形式出现——大块难以辨认的数字，只能从中提取简单的概念。
默认情况下，思维链要清晰得多，并且可以让监控模型是否存在更复杂的行为（如果它们准确地反映了模型的思维，这是一个开放的研究问题）。

ChatGPT 中出现的思路总结可能是模型可能生成违反 OpenAI 政策的内容的另一个表面。本节概述了与模型思维链相关的正在进行的研究和评估方法。


### CoT 汇总输出

在 ChatGPT 中向用户显示 CoT 摘要。利用与 o1-preview 相同的摘要生成器模型，将 o1-mini 用于初始 o1 启动。因此，在启动 o1-preview 和 o1-mini 时为摘要生成器运行的基于文本的评估表明了 o1 的相关安全风险。在撰写本文时，不会为带有图像输入的 o1 的结果生成摘要。

训练了 summarizer 模型，避免在这些摘要中生成不允许的内容。发现该模型在这里具有强大的性能。提示 o1-preview 进行标准拒绝评估，并检查摘要包含不允许的内容但答案不包含不允许的内容的情况。这表示摘要生成器引入了其他有害内容的情况。


### o1 多语言性能

为了评估 o1 模型的多语言性能，使用专业的人工翻译将 MMLU 的 [ 38] 测试集翻译成 14 种语言。
这种方法不同于 GPT-4 论文，后者使用 Azure Translate 对 MMLU 进行机器翻译 [10]。依靠人工翻译进行此评估可以提高对翻译准确性的信心，尤其是对于像 Yoruba 这样的资源匮乏的语言。

在这个测试集上评估了 o1、o1-preview、o1-mini、GPT-4o 和 GPT-4o-mini，发现 o1 和 o1-preview 表现出明显高于 GPT-4o 的多语言能力，而 o1-mini 的表现优于 GPT-4o-mini。此评估的参考代码和测试集可在 Simple Evals GitHub 存储库中找到。

Simple Evals GitHub 链接： https://www.github.com/openai/simple-evals

***对这个结果表示怀疑，用中文测试的时候，感觉它理解能力不如gpt-4o，虽然最后从编码器来看，他们都是同一个o200K的编码器***

### 结论

OpenAI o1 在上下文中执行思维链推理，从而在功能和安全基准方面都表现出色。这些增强的功能显著提高了安全基准的性能，但也增加了某些类型的风险。具体来说，通过内部评估和与外部红队成员的合作， OpenAI 准备框架内将我们的预缓解模型确定为中等风险的说服和 CBRN。

总体而言，o1 在准备框架中被归类为中等风险，已纳入相应的保障措施和安全缓解措施，为这个新的模型系列做准备。部署这些模型反映了我们的信念，即迭代实际部署是将受该技术影响的每个人都纳入 AI 安全对话的最有效方式。

